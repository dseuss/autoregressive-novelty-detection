train:
  epochs: 100
  optimizer:
    type: SGD
    lr: 0.01
    momentum: 0.9
    weight_decay: 0.0005
    nesterov: False
  scheduler:
    type: "WarmupLR"
    burn_in_steps: 1000
    after_scheduler:
      type: "StepLR"
      step_size: 4000
      gamma: 0.2

model:
  encoder:
    type: 'ResidualAE'
    input_shape: [32, 32]
    color_channels: 3
    encoder_sizes: [64, 128, 256]
    fc_sizes: [256, 64]
    latent_activation:
      type: "Sigmoid"

  regressor:
    type: 'AutoregressionModule'
    layer_sizes: [32, 32, 32, 32, 100]

  loss:
    re_weight: 0.4

data:
  batch_size_per_gpu: 16
  workers_per_gpu: 4
  __common: &common
    type: 'CIFAR10'
    positive_classes: [0, 1, 2]
  train:
    <<: *common
  valid:
    <<: *common

experiment_configurations:
  - positive_classes: [0]
  - positive_classes: [1]
  - positive_classes: [2]
  - positive_classes: [3]
  - positive_classes: [4]
  - positive_classes: [5]
  - positive_classes: [6]
  - positive_classes: [7]
  - positive_classes: [8]
  - positive_classes: [9]
